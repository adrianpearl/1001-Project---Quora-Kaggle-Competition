{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', index_col = 'qid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = df.question_text, df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def maxFscore(estimator, X, y):\n",
    "    scores = estimator.predict_proba(X)\n",
    "    pr, re, th = metrics.precision_recall_curve(y_test, scores[:,1])\n",
    "    pr, re, th = pr[:-2], re[:-2], th[:-1]\n",
    "    fs = 2*np.divide(np.multiply(pr, re), np.add(pr, re))\n",
    "    return np.max(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
    "    'vect__binary': (True, False),\n",
    "    'vect__stop_words': ['english'],\n",
    "    \n",
    "    'lr__C': (1e-2, 1e-1, 1, 10)\n",
    "}\n",
    "pgrid = ParameterGrid(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "parameters:\n",
      "{'lr__C': (0.01, 0.1, 1, 10),\n",
      " 'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
      " 'vect__stop_words': ['english']}\n",
      "testing:  {'lr__C': 0.01, 'vect__binary': True, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.5551907374605781\n",
      "testing:  {'lr__C': 0.01, 'vect__binary': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.5608747428818881\n",
      "testing:  {'lr__C': 0.01, 'vect__binary': True, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.561124588459539\n",
      "testing:  {'lr__C': 0.01, 'vect__binary': False, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 0.01, 'vect__binary': False, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.5616273056369591\n",
      "testing:  {'lr__C': 0.01, 'vect__binary': False, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.5617302493241213\n",
      "testing:  {'lr__C': 0.1, 'vect__binary': True, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.5995827819026043\n",
      "testing:  {'lr__C': 0.1, 'vect__binary': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.6093475617992705\n",
      "testing:  {'lr__C': 0.1, 'vect__binary': True, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.6094560154670884\n",
      "testing:  {'lr__C': 0.1, 'vect__binary': False, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 0.1, 'vect__binary': False, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 0.1, 'vect__binary': False, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 1, 'vect__binary': True, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 1, 'vect__binary': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.6198256348192475\n",
      "testing:  {'lr__C': 1, 'vect__binary': True, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "new best fscore:  0.6211827597728032\n",
      "testing:  {'lr__C': 1, 'vect__binary': False, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 1, 'vect__binary': False, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 1, 'vect__binary': False, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 10, 'vect__binary': True, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 10, 'vect__binary': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 10, 'vect__binary': True, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 10, 'vect__binary': False, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 10, 'vect__binary': False, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "testing:  {'lr__C': 10, 'vect__binary': False, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'}\n",
      "done in 4194.560s\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing grid search...\")\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "best_fscore = 0.0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for p in pgrid:\n",
    "    print(\"testing: \", p)\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('lr', LogisticRegression()),\n",
    "    ]).set_params(**p)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    fscore_p = maxFscore(pipeline, X_test, y_test)\n",
    "    results.append((p, fscore_p))\n",
    "    if fscore_p > best_fscore:\n",
    "        best_params = p\n",
    "        best_fscore = fscore_p\n",
    "        print(\"new best fscore: \", best_fscore)\n",
    "        \n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('lr', LogisticRegression()),\n",
    "    ]).set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        s...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pl.predict_proba(X_test)\n",
    "pr, re, th = metrics.precision_recall_curve(y_test, scores[:,1])\n",
    "pr, re, th = pr[:-2], re[:-2], th[:-1]\n",
    "fs = 2*np.divide(np.multiply(pr, re), np.add(pr, re))\n",
    "opt_th = th[np.argmax(fs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = scores[:,1] > opt_th\n",
    "cfm = metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[295580,  10674],\n",
       "       [  6334,  13943]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'lr__C': 0.01,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5551907374605781),\n",
       " ({'lr__C': 0.01,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5608747428818881),\n",
       " ({'lr__C': 0.01,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.561124588459539),\n",
       " ({'lr__C': 0.01,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5563386297625149),\n",
       " ({'lr__C': 0.01,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5616273056369591),\n",
       " ({'lr__C': 0.01,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5617302493241213),\n",
       " ({'lr__C': 0.1,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5995827819026043),\n",
       " ({'lr__C': 0.1,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6093475617992705),\n",
       " ({'lr__C': 0.1,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6094560154670884),\n",
       " ({'lr__C': 0.1,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5989228646459251),\n",
       " ({'lr__C': 0.1,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6092185285106773),\n",
       " ({'lr__C': 0.1,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6086545176041268),\n",
       " ({'lr__C': 1,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6060075037631147),\n",
       " ({'lr__C': 1,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6198256348192475),\n",
       " ({'lr__C': 1,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6211827597728032),\n",
       " ({'lr__C': 1,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.602779676463887),\n",
       " ({'lr__C': 1,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6184142879495719),\n",
       " ({'lr__C': 1,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6191154856812008),\n",
       " ({'lr__C': 10,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.588429052066913),\n",
       " ({'lr__C': 10,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6051859207767847),\n",
       " ({'lr__C': 10,\n",
       "   'vect__binary': True,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6128262764346989),\n",
       " ({'lr__C': 10,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 1),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.5840962291700466),\n",
       " ({'lr__C': 10,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 2),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6044916774530509),\n",
       " ({'lr__C': 10,\n",
       "   'vect__binary': False,\n",
       "   'vect__ngram_range': (1, 3),\n",
       "   'vect__stop_words': 'english'},\n",
       "  0.6135119236164532)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
